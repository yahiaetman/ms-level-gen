from __future__ import annotations
from dataclasses import dataclass
from common.config_tools import config
from typing import Any, List, Optional, Tuple
import warnings
import torch
from torch import nn, optim

from .models import GFlowMSGenerator

class LogZ0Net(nn.Module):
    def __init__(self, condition_size: int, hidden_size: int = 32):
        super().__init__()
        self.hidden = nn.Sequential(
            nn.Linear(condition_size, hidden_size),
            nn.LeakyReLU(inplace=True)
        )
        self.log_z0 = nn.Linear(hidden_size, 1)
        self.log_z0.weight.data.zero_()
        self.log_z0.bias.data.zero_()
    
    def forward(self, condition: torch.Tensor):
        return self.log_z0(self.hidden(condition))[:,0]

class GFlowMSTBOptimizer:
    @config
    @dataclass
    class Config:
        log_z0_hidden: int = 32
        log_z0_lr: float = 1e-2
        policy_lr: float = 1e-3
    
    @dataclass
    class Token:
        conditions: torch.tensor
        size: Tuple[int, int]
        gen_token: Any

    def __init__(self, netG: GFlowMSGenerator, sizes: List[Tuple[int, int]], config: Optional[GFlowMSTBOptimizer.Config] = None) -> None:
        self.config = config or GFlowMSTBOptimizer.Config()
        self.name = "MSTB"
        self.device = netG.device
        self.netG = netG
        self.optG = optim.RMSprop(netG.parameters(), self.config.policy_lr)
        self.netsLogZ0 = {size: LogZ0Net(netG.condition_size, self.config.log_z0_hidden).to(self.device) for size in sizes}
        self.optsLogZ0 = {size: optim.RMSprop(netLogZ0.parameters(), self.config.log_z0_lr) for size, netLogZ0 in self.netsLogZ0.items()}
        self.token = None
    
    def train(self):
        self.netG.train()
        for netLogZ0 in self.netsLogZ0.values():
            netLogZ0.train()

    def ask(self, conditions: torch.Tensor, size: Tuple[int, int]) -> torch.Tensor:
        assert size in self.netsLogZ0, "the requested size must be one of the sizes given to the trainers initializer."
        levels, gen_token = self.netG(conditions, size, generate_token=True)
        self.token = GFlowMSTBOptimizer.Token(conditions, size, gen_token)
        return levels 
    
    def tell(self, log_rewards: torch.Tensor) -> float:
        if self.token is None:
            warnings.warn("You must call ask before calling tell.")
            return
        assert self.token.conditions.shape[0] == log_rewards.shape[0], "The number of rewards must match the number of level generated by 'ask'."
        size = self.token.size
        netLogZ0 = self.netsLogZ0[size]
        optLogZ0 = self.optsLogZ0[size]
        log_z0 = netLogZ0(self.token.conditions)
        loss = self.netG.loss(self.token.gen_token, log_z0, log_rewards)
        self.optG.zero_grad()
        optLogZ0.zero_grad()
        loss.backward()
        optLogZ0.step()
        self.optG.step()
        self.token = None
        return loss.item(), log_z0.mean().item()
    
    def replay(self, conditions: torch.Tensor, targets: torch.Tensor, log_rewards: torch.Tensor) -> float:
        _, h, w = targets.shape
        size = (h, w)
        netLogZ0 = self.netsLogZ0[size]
        optLogZ0 = self.optsLogZ0[size]
        _, gen_token = self.netG.forward(conditions, targets, generate_token=True)
        log_z0 = netLogZ0(conditions)
        loss = self.netG.loss(gen_token, log_z0, log_rewards)
        self.optG.zero_grad()
        optLogZ0.zero_grad()
        loss.backward()
        optLogZ0.step()
        self.optG.step()
        return loss.item(), log_z0.mean().item()
    
    def save_checkpoint(self, path: str):
        torch.save({
            "netG": self.netG.state_dict(),
            "optG": self.optG.state_dict(),
            "netLogZ0": {size: netLogZ0.state_dict() for size, netLogZ0 in self.netsLogZ0.items()},
            "optLogZ0": {size: optLogZ0.state_dict() for size, optLogZ0 in self.optsLogZ0.items()},
        }, path)
    
    
    def load_checkpoint(self, path: str):
        data = torch.load(path)
        self.netG.load_state_dict(data["netG"])
        self.optG.load_state_dict(data["optG"])
        netLogZ0_states = data["netLogZ0"]
        optLogZ0_states = data["optLogZ0"]
        for size, netLogZ0 in self.netsLogZ0.items():
            if size in netLogZ0_states:
                netLogZ0.load_state_dict(netLogZ0_states[size])
            else:
                warnings.warn(f"netLogZ0 for the size {size} is not available in the checkpoint.")
            if size in optLogZ0_states:
                self.optsLogZ0[size].load_state_dict(optLogZ0_states[size])
            else:
                warnings.warn(f"optLogZ0 for the size {size} is not available in the checkpoint.")